{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ostro_dir = 'Osteosarcoma-UT'\n",
    "\n",
    "\n",
    "\n",
    "# Define image dimensions and batch size\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random horizontal shift\n",
    "    height_shift_range=0.2,  # Random vertical shift\n",
    "    shear_range=0.2,  # Shear transformation\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True,  # Random horizontal flip\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Viable', 'Non-Tumor', 'Non-Viable-Tumor']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Define the root directory containing subfolders for each class\n",
    "root_dir = 'Osteosarcoma-UT'\n",
    "\n",
    "# Get the list of class names\n",
    "classes = os.listdir(root_dir)\n",
    "print(classes)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = []\n",
    "val_data = []\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(root_dir, cls)\n",
    "    images = [os.path.join(cls_dir, img) for img in os.listdir(cls_dir)]\n",
    "    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    train_data.extend([(img, cls) for img in train_images])\n",
    "    val_data.extend([(img, cls) for img in val_images])\n",
    "\n",
    "# Further split the training data into training and testing sets\n",
    "train_images, test_images = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you have train_images, val_data, and test_images containing paths to images for each set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 914 validated image filenames belonging to 3 classes.\n",
      "Found 230 validated image filenames belonging to 3 classes.\n",
      "Found 183 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame with two columns: 'file_path' and 'label'\n",
    "train_df = pd.DataFrame(train_data, columns=['file_path', 'label'])\n",
    "val_df = pd.DataFrame(val_data, columns=['file_path', 'label'])\n",
    "test_df = pd.DataFrame(test_images, columns=['file_path', 'label'])\n",
    "\n",
    "# Split the data into file paths and labels\n",
    "train_data = train_df['file_path']\n",
    "train_labels = train_df['label']\n",
    "\n",
    "val_data = val_df['file_path']\n",
    "val_labels = val_df['label']\n",
    "\n",
    "test_data = test_df['file_path']\n",
    "test_labels = test_df['label']\n",
    "\n",
    "# You can create separate data generators for each set\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='file_path',\n",
    "    y_col='label',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='file_path',\n",
    "    y_col='label',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='file_path',\n",
    "    y_col='label',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 15:44:03.734415: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-21 15:44:03.734439: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-21 15:44:03.734446: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-21 15:44:03.734708: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-21 15:44:03.735179: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)         1728      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 224, 224, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " spatial_dropout2d (Spatial  (None, 224, 224, 64)         0         ['batch_normalization[0][0]'] \n",
      " Dropout2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)         36864     ['spatial_dropout2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 224, 224, 64)         256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)         0         ['batch_normalization_1[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)        73728     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 112, 112, 128)        512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (Spati  (None, 112, 112, 128)        0         ['batch_normalization_2[0][0]'\n",
      " alDropout2D)                                                       ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)        147456    ['spatial_dropout2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 112, 112, 128)        512       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)          0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)          294912    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 56, 56, 256)          1024      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (Spati  (None, 56, 56, 256)          0         ['batch_normalization_4[0][0]'\n",
      " alDropout2D)                                                       ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)          589824    ['spatial_dropout2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 56, 56, 256)          1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)          0         ['batch_normalization_5[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 512)          1179648   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 28, 28, 512)          2048      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (Spati  (None, 28, 28, 512)          0         ['batch_normalization_6[0][0]'\n",
      " alDropout2D)                                                       ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)          2359296   ['spatial_dropout2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 28, 28, 512)          2048      ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)          0         ['batch_normalization_7[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 14, 14, 1024)         4718592   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 14, 14, 1024)         4096      ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (Spati  (None, 14, 14, 1024)         0         ['batch_normalization_8[0][0]'\n",
      " alDropout2D)                                                       ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 1024)         9437184   ['spatial_dropout2d_4[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 14, 14, 1024)         4096      ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 28, 28, 512)          2097664   ['batch_normalization_9[0][0]'\n",
      " anspose)                                                           ]                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 28, 1024)         0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 512)          4718592   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 28, 28, 512)          2048      ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)          2359296   ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 28, 28, 512)          2048      ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 56, 56, 256)          524544    ['batch_normalization_11[0][0]\n",
      " Transpose)                                                         ']                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 56, 56, 512)          0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 56, 56, 256)          1179648   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 56, 56, 256)          1024      ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 56, 56, 256)          589824    ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 56, 56, 256)          1024      ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 112, 112, 128)        131200    ['batch_normalization_13[0][0]\n",
      " Transpose)                                                         ']                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 112, 112, 256)        0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 112, 112, 128)        294912    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 112, 112, 128)        512       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 112, 112, 128)        147456    ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 112, 112, 128)        512       ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2D  (None, 224, 224, 64)         32832     ['batch_normalization_15[0][0]\n",
      " Transpose)                                                         ']                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 224, 224, 128)        0         ['conv2d_transpose_3[0][0]',  \n",
      " )                                                                   'batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 224, 224, 64)         73728     ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 224, 224, 64)         256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 224, 224, 64)         36864     ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 224, 224, 64)         256       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 224, 224, 3)          195       ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31049539 (118.44 MB)\n",
      "Trainable params: 31037763 (118.40 MB)\n",
      "Non-trainable params: 11776 (46.00 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, None, None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     31\u001b[0m     train_generator,\n\u001b[1;32m     32\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_generator),\n\u001b[1;32m     33\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     34\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[1;32m     35\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(validation_generator),\n\u001b[1;32m     36\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]\n\u001b[1;32m     37\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/yd/6l3qbbqj2qx_y_lxrr45xd480000gn/T/__autograph_generated_filec48tlnk2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/uvaishnav/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, None) and (None, None, None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from keras_unet.models import custom_unet\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "# Define the input shape (assuming 224x224 images)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the number of classes in your segmentation task\n",
    "num_classes = 3  # Adjust this according to your task\n",
    "\n",
    "# Load the pre-trained U-Net model\n",
    "model = custom_unet(\n",
    "    input_shape,\n",
    "    filters=64,\n",
    "    num_classes=num_classes,\n",
    "    output_activation='softmax'  # Use softmax activation for multi-class segmentation\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(), \n",
    "    loss='categorical_crossentropy',  # Use categorical cross-entropy for multi-class segmentation\n",
    "    metrics=['accuracy', MeanIoU(num_classes=num_classes)]\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 373ms/step - loss: 0.1911 - accuracy: 0.9250\n",
      "Test accuracy: 0.925000011920929\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
